{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import 需要的库\n",
    "在执行此note前，先启动环境, 在windows命令提示符下执行:\n",
    "```\n",
    "conda env list\n",
    "activate dlnd-tf-lab\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'models' from 'E:\\\\My_study_place\\\\python\\\\jupyter\\\\kaggle\\\\Human Protein Atlas Image Classification\\\\models.py'>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import fnmatch\n",
    "import math\n",
    "from keras.layers import *\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import callbacks\n",
    "\n",
    "import utils, models\n",
    "import importlib\n",
    "importlib.reload(utils)\n",
    "importlib.reload(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the training data for training\n",
    "- split the data\n",
    "- build model and do training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category:  Actin filaments ,trainSize: 11 ,validSize: 4\n",
      "category:  Aggresome ,trainSize: 2 ,validSize: 0\n",
      "category:  Cell junctions ,trainSize: 7 ,validSize: 3\n",
      "category:  Centrosome ,trainSize: 16 ,validSize: 6\n",
      "category:  Cytokinetic bridge ,trainSize: 12 ,validSize: 4\n",
      "category:  Cytoplasmic bodies ,trainSize: 7 ,validSize: 2\n",
      "category:  Cytosol ,trainSize: 140 ,validSize: 59\n",
      "category:  Endoplasmic reticulum ,trainSize: 14 ,validSize: 5\n",
      "category:  Endosomes ,trainSize: 2 ,validSize: 0\n",
      "category:  Focal adhesion sites ,trainSize: 6 ,validSize: 2\n",
      "category:  Golgi apparatus ,trainSize: 40 ,validSize: 17\n",
      "category:  Intermediate filaments ,trainSize: 16 ,validSize: 6\n",
      "category:  Lipid droplets ,trainSize: 3 ,validSize: 1\n",
      "category:  Lysosomes ,trainSize: 2 ,validSize: 0\n",
      "category:  Microtubule ends ,trainSize: 0 ,validSize: 0\n",
      "category:  Microtubule organizing center ,trainSize: 17 ,validSize: 7\n",
      "category:  Microtubules ,trainSize: 17 ,validSize: 7\n",
      "category:  Mitochondria ,trainSize: 42 ,validSize: 18\n",
      "category:  Mitotic spindle ,trainSize: 7 ,validSize: 3\n",
      "category:  Nuclear bodies ,trainSize: 42 ,validSize: 18\n",
      "category:  Nuclear membrane ,trainSize: 14 ,validSize: 5\n",
      "category:  Nuclear speckles ,trainSize: 31 ,validSize: 13\n",
      "category:  Nucleoli ,trainSize: 49 ,validSize: 20\n",
      "category:  Nucleoli fibrillar center ,trainSize: 29 ,validSize: 12\n",
      "category:  Nucleoplasm ,trainSize: 194 ,validSize: 82\n",
      "category:  Peroxisomes ,trainSize: 1 ,validSize: 0\n",
      "category:  Plasma membrane ,trainSize: 65 ,validSize: 27\n",
      "category:  Rods & rings ,trainSize: 1 ,validSize: 0\n"
     ]
    }
   ],
   "source": [
    "# Split the data\n",
    "def splitCategoryTrainValid(categoryName, categorizedDir=\"./categorizedTrain\", trainDir=\"./train\",\n",
    "                      testPercent=0.3, randomSeed=None, createLink=False):\n",
    "    \"\"\" \n",
    "    # Description: split the data in categorizedDir to train and valid based on testPercent\n",
    "    # Arguments\n",
    "        categoryName: name of category to be splited\n",
    "        categorizedDir: the directory in which data that already been categorized have been saved\n",
    "        trainDir: the directory that will be used to save the training data, there will be two subdir names 'train', 'valid' in it\n",
    "        testPercent: the percentage of data that will be used to do validation\n",
    "        randomSeed: random seed for the split\n",
    "        createLink: whether to create a link to the target file or just copy it.\n",
    "    # Returns\n",
    "        trainSize: the # of samples that splited for training\n",
    "        validSize: the # of samples that splited for validation\n",
    "    # Raises\n",
    "        None\n",
    "    \n",
    "    \"\"\"\n",
    "    if testPercent <=0 or testPercent >=1:\n",
    "        raise Exception(\"\\n testPercent must be in (0,1)\")\n",
    "        \n",
    "    sourceDir = os.path.join(categorizedDir, categoryName)\n",
    "    destTrainDir = os.path.join(trainDir , \"train\", categoryName)\n",
    "    destValidDir = os.path.join(trainDir , \"valid\", categoryName)\n",
    "    \n",
    "    fileNames = os.listdir(sourceDir)\n",
    "    totalSize = len(fileNames)\n",
    "    testSize = int(totalSize * testPercent)\n",
    "    trainSize = totalSize - testSize\n",
    "    \n",
    "    if not randomSeed is None:\n",
    "        random.seed(randomSeed)\n",
    "    random.shuffle(fileNames)\n",
    "    utils.rebuildDir(destTrainDir)\n",
    "    utils.rebuildDir(destValidDir)\n",
    "    for i in range(0, totalSize):\n",
    "        if i < testSize:\n",
    "            destDir = destValidDir\n",
    "        else:\n",
    "            destDir = destTrainDir\n",
    "        \n",
    "        if createLink == True:\n",
    "                os.symlink(os.path.join(sourceDir, fileNames[i]), os.path.join(destDir, fileNames[i]))\n",
    "        else:\n",
    "                shutil.copy(os.path.join(sourceDir, fileNames[i]), destDir)\n",
    "                \n",
    "    return trainSize, testSize\n",
    "\n",
    "def splitAllTrainValid(categorizedDir=\"./categorizedTrain\", trainDir=\"./train\",\n",
    "                      testPercent=0.3, randomSeed=None, createLink=False):\n",
    "    \"\"\" \n",
    "    # Description: split the data in categorizedDir to train and valid based on testPercent\n",
    "    # Arguments\n",
    "        categorizedDir: the directory in which data that already been categorized have been saved\n",
    "        trainDir: the directory that will be used to save the training data, there will be two subdir names 'train', 'valid' in it\n",
    "        testPercent: the percentage of data that will be used to do validation\n",
    "        randomSeed: random seed for the split\n",
    "        createLink: whether to create a link to the target file or just copy it.\n",
    "    # Returns\n",
    "        None\n",
    "    # Raises\n",
    "        None\n",
    "    \"\"\"\n",
    "    categories = os.listdir(categorizedDir)\n",
    "    for categoryName in categories:\n",
    "        trainSize, validSize = splitCategoryTrainValid(categoryName, categorizedDir, trainDir, testPercent, randomSeed, createLink)\n",
    "        print(\"category: \", categoryName, \",trainSize:\", trainSize, \",validSize:\", validSize)\n",
    "    \n",
    "#test\n",
    "splitCategoryTrainValid(\"Nucleoli\")\n",
    "\n",
    "splitAllTrainValid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getDataSize(dir, filterPattern):\n",
    "    subDirs = os.listdir(dir)\n",
    "    sum = 0\n",
    "    for subdir in subDirs:\n",
    "        sum += len(fnmatch.filter(os.listdir(os.path.join(dir, subdir)),filterPattern))\n",
    "    return sum\n",
    "\n",
    "def doTraining(model, modelName, epoch, imageSize, numPerbatch, \n",
    "               trainDir,validDir, filterPattern):\n",
    "    \"\"\"\n",
    "    # Description: \n",
    "    # Arguments\n",
    "        \n",
    "    # Returns\n",
    "        None\n",
    "    # Raises\n",
    "        None\n",
    "    \"\"\"\n",
    "    trainSize = getDataSize(trainDir, filterPattern)\n",
    "    validSize = getDataSize(validDir, filterPattern)\n",
    "    \n",
    "    trainDataGen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        data_format='channels_last') \n",
    "    validDataGen = ImageDataGenerator(rescale=1./255,\n",
    "                           data_format='channels_last')\n",
    "   \n",
    "    trainGenerator = trainDataGen.flow_from_directory(\n",
    "       trainDir,\n",
    "       target_size=imageSize,\n",
    "       batch_size = numPerbatch,\n",
    "       shuffle = True,\n",
    "       class_mode='binary')\n",
    "    validGenerator = validDataGen.flow_from_directory( \n",
    "       validDir,\n",
    "       target_size=imageSize,\n",
    "       batch_size = numPerbatch,\n",
    "       shuffle = True,\n",
    "       class_mode='binary')\n",
    "\n",
    "    \n",
    "    '''\n",
    "    The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number     of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. \n",
    "    Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed.\n",
    "    '''\n",
    "    # logLocation = \"./\" + modelName\n",
    "    # tensorBoard = callbacks.TensorBoard(log_dir=logLocation)\n",
    "    # earlyStopping = callbacks.EarlyStopping(monitor='val_loss', patience=5)  \n",
    "    filePath = \"./\" + modelName + \"_top.h5\"\n",
    "    checkPoint = callbacks.ModelCheckpoint(filePath, \"val_loss\", verbose=1, save_best_only=True)\n",
    "    # callBacks = [tensorBoard, earlyStopping, checkPoint]\n",
    "    callBacks = [checkPoint]\n",
    "    \n",
    "    \n",
    "    history = model.fit_generator(trainGenerator,\n",
    "                steps_per_epoch = math.ceil(trainSize / numPerbatch), \n",
    "                epochs = epoch,\n",
    "                validation_data=validGenerator,\n",
    "                validation_steps = math.ceil(validSize / numPerbatch),\n",
    "                callbacks=callBacks)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 787 images belonging to 28 classes.\n",
      "Found 321 images belonging to 28 classes.\n",
      "Epoch 1/10\n",
      "16/22 [====================>.........] - ETA: 97s - loss: 3.0769 - acc: 0.2344      \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    }
   ],
   "source": [
    "imageShape=(512,512,3)\n",
    "labelSize = 28\n",
    "modelName = \"modelC7D3\"\n",
    "perbatch = 16\n",
    "pochNum = 5\n",
    "# TODO: replace all the trainDataDir and above variables\n",
    "trainDataDir = \"./train/train\"\n",
    "validDataDir = \"./train/valid\"\n",
    "\n",
    "modelC7D3 = models.modelC7D3(imageShape, labelSize)\n",
    "# modelC7D3.summary()\n",
    "adam = optimizers.Adam(lr=0.0001)\n",
    "rmsp = optimizers.RMSprop(lr=0.0001)\n",
    "modelC7D3.compile(optimizer=adam, loss=losses.sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "# ModelUtil.visualize_model(modelC7D3, model_name=modelName)\n",
    "modelHistory = doTraining(modelC7D3, modelName=modelName, epoch=pochNum,\n",
    "                          imageSize = (imageShape[:-1]), numPerbatch=perbatch,\n",
    "                          trainDir=trainDataDir, validDir=validDataDir,filterPattern=\"*_green.png\")\n",
    "# ModelUtil.visualize_history(history_case2_tune1, model_name=name_case2_tune1)\n",
    "with open(modelName+'.pickle', 'wb') as f:\n",
    "    pickle.dump(modelHistory.history, f)\n",
    "# ModelUtil.save_model(modelC7D3, model_name=modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
