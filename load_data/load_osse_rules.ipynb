{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##ossec-hids中的rule配置和测试数据可用于日志分析\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import xml.etree.ElementTree as ET\n",
    "import xmltodict, json\n",
    "import pandas as pd\n",
    "import collections\n",
    "import re\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "pd.options.display.max_colwidth = 1000\n",
    "filepath = r\"F:\\open-source-check\\ossec-xml\"\n",
    "EXCLUDE_FILES=[\"decode.xml\",\n",
    "              \"local_rules.xml\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfilelist = getAllXMLFiles(filepath)\\nfor file in filelist:\\n    print(file)\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getAllXMLFiles(destPath):\n",
    "    filelist = []\n",
    "    for f in listdir(destPath):\n",
    "        if not isfile(join(destPath, f)):\n",
    "            continue\n",
    "            \n",
    "        if not f.endswith(\"rules_en.xml\") \\\n",
    "            and not f.endswith(\"rules.xml\"):\n",
    "                continue\n",
    "        if f in EXCLUDE_FILES:\n",
    "            continue\n",
    "            \n",
    "        filelist.append(f)\n",
    "    \n",
    "    return filelist\n",
    "\n",
    "\"\"\"\n",
    "filelist = getAllXMLFiles(filepath)\n",
    "for file in filelist:\n",
    "    print(file)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parseXMLToPd(file): \n",
    "    try:\n",
    "        with open(file, \"r\", encoding='utf-8') as fd:\n",
    "            #https://github.com/martinblech/xmltodict/issues/2\n",
    "            data = xmltodict.parse('<root>{0}</root>'.format(fd.read()))['root']\n",
    "\n",
    "            #get all the vars\n",
    "            df_vars = pd.DataFrame()\n",
    "            if \"var\" in data:\n",
    "                try:\n",
    "                    df_vars = pd.DataFrame(json_normalize(data[\"var\"]))\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    raise e\n",
    "            \n",
    "            #replace all the vars in jsonStr\n",
    "            jsonData = json.dumps(data[\"group\"], indent=4)\n",
    "            for index, row in df_vars.iterrows():\n",
    "                key, value = row[\"@name\"], row[\"#text\"]\n",
    "                #for Unrecognized escape sequence\n",
    "                value = re.sub(r\"([\\\\\\/])\", r\"\\\\\\1\", value)\n",
    "                jsonData = jsonData.replace('$'+key, value)\n",
    "                \n",
    "            #print(jsonData)  \n",
    "            return pd.read_json(jsonData)\n",
    "    except Exception as e:\n",
    "        print(file)\n",
    "        raise e\n",
    "    \n",
    "    return None\n",
    "    \n",
    "#print(parseXMLToPd(join(filepath, \"web_appsec_rules.xml\")).head())\n",
    "#print(parseXMLToPd(join(filepath, \"syslog_rules.xml\")).head())\n",
    "#print(parseXMLToPd(join(filepath, \"mcafee_av_rules.xml\")).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1063, 2)\n"
     ]
    }
   ],
   "source": [
    "filelist = getAllXMLFiles(filepath)\n",
    "df = pd.DataFrame()\n",
    "for file in filelist:\n",
    "    df_tmp = parseXMLToPd(join(filepath, file))\n",
    "    if df_tmp is not None:\n",
    "        df = df.append(df_tmp, ignore_index=True)\n",
    "print(df.shape)\n",
    "df.to_csv(\"ossec_rules.csv\", sep=',', encoding='utf-8', index=False)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  group_name      body                     description\n",
      "0    apache,  ^[error]  Apache error messages grouped.\n",
      "Index(['group_name', 'body', 'description'], dtype='object')\n",
      "(661, 3)\n",
      "Index(['@frequency', '@id', '@ignore', '@level', '@maxsize', '@noalert',\n",
      "       '@timeframe', 'action', 'category', 'check_diff', 'check_if_ignored',\n",
      "       'compiled_rule', 'decoded_as', 'description', 'different_url',\n",
      "       'extra_data', 'group', 'group_name', 'hostname', 'id', 'if_fts',\n",
      "       'if_group', 'if_matched_group', 'if_matched_sid', 'if_sid', 'ignore',\n",
      "       'info', 'info.#text', 'info.@type', 'match', 'options', 'program_name',\n",
      "       'regex', 'regex.#text', 'regex.@offet', 'same_id', 'same_source_ip',\n",
      "       'same_user', 'status', 'time', 'url', 'user', 'weekday'],\n",
      "      dtype='object')\n",
      "(1197, 43)\n"
     ]
    }
   ],
   "source": [
    "df_keep = pd.DataFrame()\n",
    "df_bak = pd.DataFrame()\n",
    "for index, row in df.iterrows():\n",
    "    group_name = row[\"@name\"]\n",
    "    rules = row[\"rule\"]\n",
    "    df_tmp = None\n",
    "    try:\n",
    "        df_tmp = pd.DataFrame(json_normalize(rules))\n",
    "        df_tmp[\"group_name\"] = group_name\n",
    "        df_bak = df_bak.append(df_tmp, ignore_index=True)\n",
    "        keep_columns = [\"group_name\", \"body\"]\n",
    "        if \"description\" in df_tmp.columns:\n",
    "            keep_columns.append(\"description\")\n",
    "            \n",
    "        join_columns = []\n",
    "        if \"match\" in df_tmp.columns:\n",
    "            join_columns.append(\"match\")\n",
    "        elif \"regex\" in df_tmp.columns:\n",
    "            join_columns.append(\"regex\")\n",
    "            if \"regex.#text\" in df_tmp.columns:\n",
    "                join_columns.append(\"regex.#text\")\n",
    "        else:\n",
    "            continue\n",
    "        df_tmp[\"body\"] = df_tmp[join_columns].apply(lambda x: ','.join(x.dropna().astype(str)),axis=1)\n",
    "        #df_tmp[\"body\"] = df_tmp[keep_columns].stack().values\n",
    "\n",
    "        df_keep = df_keep.append(df_tmp[keep_columns], ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(rules)\n",
    "        print(df_tmp)\n",
    "        print(e)\n",
    "        \n",
    "print(df_keep.head(1))\n",
    "print(df_keep.columns)\n",
    "print(df_keep.shape)\n",
    "print(df_bak.columns)\n",
    "print(df_bak.shape)\n",
    "df_keep.to_csv(\"ossec_rules_keep.csv\", sep=',', encoding='utf-8', index=False)   \n",
    "#print(df_keep[df_keep[\"@id\"] == \"7300\"][[\"@id\", \"@level\", \"decoded_as\", \"description\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
