{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)\n",
      "==========feature names=========\n",
      "['did', 'favor', 'get', 'go', 'hey', 'home', 'lets', 'lunch', 'need', 'today', 'you']\n"
     ]
    }
   ],
   "source": [
    "messages = [\"Hey hey hey lets go get lunch today :)\",\n",
    "           \"Did you go home?\",\n",
    "           \"Hey!!! I need a favor\"]\n",
    "vect = CountVectorizer()\n",
    "vect.fit(messages)\n",
    "print(vect)\n",
    "print(\"==========feature names=========\")\n",
    "print(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 由上面的结果可知，主要作了以下处理:\n",
    "- 单词全部转换为小写\n",
    "- 小于2个字符的单词被过滤掉\n",
    "- 删除了puncutation\n",
    "- 单词去重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t3\n",
      "  (0, 6)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 9)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 5)\t1\n",
      "  (1, 10)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 4)\t1\n",
      "  (2, 8)\t1\n",
      "==========term frequency matrix=========\n",
      "   did  favor  get  go  hey  home  lets  lunch  need  today  you\n",
      "0    0      0    1   1    3     0     1      1     0      1    0\n",
      "1    1      0    0   1    0     1     0      0     0      0    1\n",
      "2    0      1    0   0    1     0     0      0     1      0    0\n"
     ]
    }
   ],
   "source": [
    "## fit 是用于拟合向量器的，当拟合过后，就可以用向量器来向量化文本。\n",
    "dtm = vect.transform(messages)\n",
    "print(dtm)\n",
    "data = pd.DataFrame(dtm.toarray(), columns=vect.get_feature_names())\n",
    "print(\"==========term frequency matrix=========\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 6)\t1\n",
      "   did  favor  get  go  hey  home  lets  lunch  need  today  you\n",
      "0    0      0    1   1    1     0     1      0     0      0    0\n"
     ]
    }
   ],
   "source": [
    "## 要注意的是，如果新的message里包含有己经拟合的vect中没有的单词，新的单词不会被加到结果\n",
    "new_message=['Hey lets go get a drink tonight']\n",
    "new_dtm = vect.transform(new_message)\n",
    "print(new_dtm)\n",
    "new_data = pd.DataFrame(new_dtm.toarray(), columns=vect.get_feature_names())\n",
    "print(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   did  drink  favor  get  go  hey  home  lets  lunch  need  today  tonight  \\\n",
      "0    0      0      0    1   1    3     0     1      1     0      1        0   \n",
      "1    1      0      0    0   1    0     1     0      0     0      0        0   \n",
      "2    0      0      1    0   0    1     0     0      0     1      0        0   \n",
      "3    0      1      0    1   1    1     0     1      0     0      0        1   \n",
      "\n",
      "   you  \n",
      "0    0  \n",
      "1    1  \n",
      "2    0  \n",
      "3    0  \n"
     ]
    }
   ],
   "source": [
    "### 全量拟合\n",
    "messages.extend(new_message)\n",
    "vect.fit(messages)\n",
    "dtm = vect.transform(messages)\n",
    "data = pd.DataFrame(dtm.toarray(), columns = vect.get_feature_names())\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 关于new_message里有新字段\n",
    "这在做文档预测时，过滤掉测试集里在训练集里没有的字段，并不会有什么影响，因为即使加进去，训练出来的字段对应的权重w也是0。\n",
    "伪代码:\n",
    "    # creating DTMs\n",
    "    vect = CountVectorizer()\n",
    "    X_train_dtm = vect.fit_transform(X_train)\n",
    "    X_test_dtm = vect.fit(X_test)\n",
    "    \n",
    "    #creating and training logistic regression model\n",
    "    logreg = LogisticRegression()\n",
    "    logreg.fit(X_train_dtm, y_train)\n",
    "    y_predicted = logreg.predict(X_test_dtm)  # predicting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
